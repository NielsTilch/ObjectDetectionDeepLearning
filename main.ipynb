{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkMIXORSyicb"
      },
      "source": [
        "**NB : Ne pas oublier de mettre l'accélération GPU**\n",
        "\n",
        "*Chemin : Runtime --> Change Runtime Type*\n",
        "\n",
        "\n",
        "Pour lancer le programme, appuyer sur le bouton tout en haut à gauche du carré noir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chg724SHZLaG"
      },
      "source": [
        "# **Programme Principal (pour l'ensemble des tests)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "vgfmHHBWy-f_",
        "outputId": "4e14afc2-ea7a-4ffe-91d8-28e3bb8fd307"
      },
      "source": [
        "#Importing necessary package\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import *\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "from random import sample, randint\n",
        "\n",
        "#Link to all of the dataset example :\n",
        "# mnist : https://deepai.org/dataset/mnist\n",
        "# cifar10 : https://www.tensorflow.org/datasets/catalog/cifar10\n",
        "# cifar100 : https://paperswithcode.com/dataset/cifar-100\n",
        "\n",
        "#Function use to test the build neural network on the mnist dataset \n",
        "#Entry variable : Number of epochs (number of time learning the same set)\n",
        "\n",
        "def mnisttest(Nombre_epochs):\n",
        "  \n",
        "  (train_images_mnist, train_labels_mnist), (test_images_mnist, test_labels_mnist) = mnist.load_data()\n",
        "\n",
        "\n",
        "  #On normalise les valeurs des pixels pour les mettre entre 0 et 1\n",
        "  train_images_mnist = train_images_mnist/255\n",
        "  test_images_mnist = test_images_mnist/255\n",
        "\n",
        "\n",
        "\n",
        "  #On créé le réseau de neurones\n",
        "  #----------------------\n",
        "  #The neural network\n",
        "  #----------------------\n",
        "  modelCNN = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(64,3,padding=\"same\",input_shape=(28,28,1),activation=\"relu\",kernel_regularizer=l2(0.0005)),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(48,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(31,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(10,activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #On compile le réseau\n",
        "  modelCNN.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics = [\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  #On augmente la dimensions des matrices d'entrainement et de test pour pouvoir les faire rentrer dans le réseau\n",
        "  train_images_mnist = np.expand_dims(train_images_mnist,3)\n",
        "  test_images_mnist = np.expand_dims(test_images_mnist,3)\n",
        "  list_images = list(test_images_mnist)\n",
        "  random_image = sample(list_images, 1)\n",
        "  random_image = np.array(random_image, dtype='float')\n",
        "\n",
        "  #On entraine le modèle\n",
        "  history = modelCNN.fit(\n",
        "      train_images_mnist,\n",
        "      train_labels_mnist,\n",
        "      validation_data=(test_images_mnist, test_labels_mnist),\n",
        "      epochs = Nombre_epochs\n",
        "  )\n",
        "  train_images_mnist = np.expand_dims(train_images_mnist,4)\n",
        "  predictions = modelCNN.predict(test_images_mnist)\n",
        "\n",
        "  labels = [0,1,2,3,4,5,6,7,8,9]\n",
        "  i=0;\n",
        "  pred = np.zeros(len(predictions))\n",
        "  for x in predictions :\n",
        "    pred[i] = np.argmax(x)\n",
        "    i=i+1\n",
        "\n",
        "\n",
        "  #On créé la matrice de confusion pour observer les positifs et les négatifs\n",
        "  cm = tf.math.confusion_matrix(test_labels_mnist, pred)\n",
        " \n",
        "  plt.figure(figsize=(9,9))\n",
        "  sns.heatmap(cm, cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot=True, cmap=plt.cm.Blues)\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('Actual')\n",
        "  plt.show()\n",
        "\n",
        "  #Showing the results\n",
        "  x_axis = np.linspace(2,Nombre_epochs+1,1)\n",
        "  plt.plot(history.history['accuracy'],label = \"Précision de l'entrainement\")\n",
        "  plt.plot(history.history['val_accuracy'],label=\"Précision des tests\")\n",
        "  plt.title(\"Valeur de la précision de l'entrainement et de l'évaluation en fonction des epochs\")\n",
        "  plt.xlabel(\"Nombre d'epochs\")\n",
        "  plt.ylabel(\"Taux de précision\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  #Evaluation du model avec les données tests\n",
        "  modelCNN.evaluate(test_images_mnist, test_labels_mnist)\n",
        "\n",
        "  #Boucle pour les tests de reconnaissance\n",
        "  while (True):\n",
        "    random_image = sample(list_images, 1)\n",
        "    random_image = np.array(random_image, dtype='float')\n",
        "\n",
        "    predict_random = modelCNN.predict(random_image)\n",
        "\n",
        "    random_pred = str(np.argmax(predict_random))\n",
        "\n",
        "    random_image = random_image.reshape((28, 28))\n",
        "    plt.imshow(random_image)\n",
        "    plt.title(\"résultat prédit : \" + random_pred)\n",
        "    plt.show()\n",
        "\n",
        "    if input(\"Afficher un autre exemple ? oui/non : \") == \"non\":\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "#Function use to test the build neural network on the cifar dataset \n",
        "#For this function, we pre-process the image in black and white to see\n",
        "#how the black white preprocessing affect the accuracy.\n",
        "\n",
        "#Entry variable : Number of epochs (number of time learning the same set)\n",
        "\n",
        "def cifar10testgris(Nombre_epochs):\n",
        "  \n",
        "  \n",
        "  (train_images_cifar10, train_labels_cifar10), (test_images_cifar10, test_labels_cifar10) = cifar10.load_data()\n",
        "\n",
        "  #Passage au niveau de gris\n",
        "  train_images_cifar10 = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in train_images_cifar10])\n",
        "  test_images_cifar10 = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in test_images_cifar10])\n",
        "\n",
        "\n",
        "\n",
        "  #On normalise les valeurs des pixels pour les mettre entre 0 et 1\n",
        "  train_images_cifar10 = train_images_cifar10/255\n",
        "  test_images_cifar10 = test_images_cifar10/255\n",
        "\n",
        "\n",
        "  #On créé le réseau de neurones\n",
        "  #----------------------\n",
        "  #The neural network\n",
        "  #----------------------\n",
        "  modelCNN = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(128,3,padding=\"same\",input_shape=(32,32,1),activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(64,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(16,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(10,activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  #On augmente la dimensions des matrices d'entrainement et de test pour pouvoir les faire rentrer dans le réseau\n",
        "  train_images_cifar10 = np.expand_dims(train_images_cifar10,3)\n",
        "  test_images_cifar10 = np.expand_dims(test_images_cifar10,3)\n",
        "\n",
        "  #On compile le réseau\n",
        "  modelCNN.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics = [\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  #On entraine le modèle\n",
        "  history = modelCNN.fit(\n",
        "      train_images_cifar10,\n",
        "      train_labels_cifar10,\n",
        "      validation_data=(test_images_cifar10, test_labels_cifar10),\n",
        "      epochs = Nombre_epochs\n",
        "  )\n",
        "\n",
        "  modelCNN.evaluate(test_images_cifar10, test_labels_cifar10)\n",
        "\n",
        "  x_axis = np.linspace(2,Nombre_epochs+1,1)\n",
        "  plt.plot(history.history['accuracy'],label = \"Précision de l'entrainement\")\n",
        "  plt.plot(history.history['val_accuracy'],label=\"Précision des tests\")\n",
        "  plt.title(\"Valeur de la précision de l'entrainement et de l'évaluation en fonction des epochs\")\n",
        "  plt.xlabel(\"Nombre d'epochs\")\n",
        "  plt.ylabel(\"Taux de précision\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "#Function use to test the build neural network on the cifar10 dataset \n",
        "#Entry variable : Number of epochs (number of time learning the same set)\n",
        "\n",
        "def cifar10test(Nombre_epochs):\n",
        "  \n",
        "  \n",
        "  (train_images_cifar10, train_labels_cifar10), (test_images_cifar10, test_labels_cifar10) = cifar10.load_data()\n",
        "\n",
        "  #On normalise les valeurs des pixels pour les mettre entre 0 et 1\n",
        "  train_images_cifar10 = train_images_cifar10/255\n",
        "  test_images_cifar10 = test_images_cifar10/255\n",
        "\n",
        "\n",
        "\n",
        "  #On créé le réseau de neurones\n",
        "  #----------------------\n",
        "  #The neural network\n",
        "  #----------------------\n",
        "  modelCNN = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(128,3,padding=\"same\",input_shape=(32,32,3),activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(64,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(16,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(10,activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "\n",
        "  #On compile le réseau\n",
        "  modelCNN.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics = [\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  #On entraine le modèle\n",
        "  history = modelCNN.fit(\n",
        "      train_images_cifar10,\n",
        "      train_labels_cifar10,\n",
        "      validation_data = (test_images_cifar10, test_labels_cifar10),\n",
        "      epochs = Nombre_epochs\n",
        "  )\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #Showing the results\n",
        "  x_axis = np.linspace(2,Nombre_epochs+1,1)\n",
        "  plt.plot(history.history['accuracy'],label = \"Précision de l'entrainement\")\n",
        "  plt.plot(history.history['val_accuracy'],label=\"Précision des tests\")\n",
        "  plt.title(\"Valeur de la précision de l'entrainement et de l'évaluation en fonction des epochs\")\n",
        "  plt.xlabel(\"Nombre d'epochs\")\n",
        "  plt.ylabel(\"Taux de précision\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "\n",
        "#Function use to test the build neural network on the cifar100 dataset \n",
        "#For this function, we pre-process the image in black and white to see\n",
        "#how the black white preprocessing affect the accuracy.\n",
        "\n",
        "#Entry variable : Number of epochs (number of time learning the same set)\n",
        "\n",
        "def cifar100testgris(Nombre_epochs):\n",
        "\n",
        "\n",
        "  (train_images_cifar100, train_labels_cifar100), (test_images_cifar100, test_labels_cifar100) = cifar10.load_data()\n",
        "\n",
        "  train_images_cifar100 = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in train_images_cifar100])\n",
        "  test_images_cifar100 = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in test_images_cifar100])\n",
        "\n",
        "  #On normalise les valeurs des pixels pour les mettre entre 0 et 1\n",
        "  train_images_cifar100 = train_images_cifar100/255\n",
        "  test_images_cifar100 = test_images_cifar100/255\n",
        "\n",
        "\n",
        "\n",
        "  #On créé le réseau de neurones\n",
        "  #----------------------\n",
        "  #The neural network\n",
        "  #----------------------\n",
        "  modelCNN = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(64,3,padding=\"same\",input_shape=(32,32,1),activation=\"relu\",kernel_regularizer=l2(0.0005)),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(48,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(16,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100,activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "\n",
        "  train_images_cifar100 = np.expand_dims(train_images_cifar100,3)\n",
        "  test_images_cifar100 = np.expand_dims(test_images_cifar100,3)\n",
        "\n",
        "  #On compile le réseau\n",
        "  modelCNN.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics = [\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  #On augmente la dimensions des matrices d'entrainement et de test pour pouvoir les faire rentrer dans le réseau\n",
        "  train_images_cifar100 = np.expand_dims(train_images_cifar100,3)\n",
        "  test_images_cifar100 = np.expand_dims(test_images_cifar100,3)\n",
        "\n",
        "  #On entraine le modèle\n",
        "  history = modelCNN.fit(\n",
        "      train_images_cifar100,\n",
        "      train_labels_cifar100,\n",
        "      validation_data = (test_images_cifar100, test_labels_cifar100),\n",
        "      epochs = Nombre_epochs\n",
        "  )\n",
        "\n",
        "  #Showing results\n",
        "  x_axis = np.linspace(2,Nombre_epochs+1,1)\n",
        "  plt.plot(history.history['accuracy'],label = \"Précision de l'entrainement\")\n",
        "  plt.plot(history.history['val_accuracy'],label=\"Précision des tests\")\n",
        "  plt.title(\"Valeur de la précision de l'entrainement et de l'évaluation en fonction des epochs\")\n",
        "  plt.xlabel(\"Nombre d'epochs\")\n",
        "  plt.ylabel(\"Taux de précision\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  labels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'];\n",
        "  list_images = list(test_images)\n",
        "  while (True):\n",
        "    random_image = sample(list_images, 1)\n",
        "    random_image = np.array(random_image, dtype='float')\n",
        "\n",
        "    predict_random = modelCNN.predict(random_image)\n",
        "\n",
        "    random_pred = np.argmax(predict_random)\n",
        "\n",
        "    random_image = random_image.reshape((32, 32))\n",
        "    plt.imshow(random_image)\n",
        "    plt.title(\"résultat prédit : \" + str(labels[random_pred]))\n",
        "    plt.show()\n",
        "\n",
        "    if input(\"Afficher un autre exemple ? oui/non : \") == \"non\":\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "#Function use to test the build neural network on the cifar100 dataset \n",
        "#Entry variable : Number of epochs (number of time learning the same set)\n",
        "\n",
        "def cifar100test(Nombre_epochs):\n",
        "\n",
        "\n",
        "  (train_images_cifar100, train_labels_cifar100), (test_images_cifar100, test_labels_cifar100) = cifar100.load_data()\n",
        "\n",
        "  #On normalise les valeurs des pixels pour les mettre entre 0 et 1\n",
        "  train_images_cifar100 = train_images_cifar100/255\n",
        "  test_images_cifar100 = test_images_cifar100/255\n",
        "\n",
        "\n",
        "\n",
        "  #On créé le réseau de neurones\n",
        "  #----------------------\n",
        "  #The neural network\n",
        "  #----------------------\n",
        "  modelCNN = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(64,3,padding=\"same\",input_shape=(32,32,3),activation=\"relu\",kernel_regularizer=l2(0.0005)),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(48,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(16,3,padding=\"same\",activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100,activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "\n",
        "\n",
        "  #On compile le modèle\n",
        "  modelCNN.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics = [\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  #On entraine le modèle\n",
        "  history = modelCNN.fit(\n",
        "      train_images_cifar100,\n",
        "      train_labels_cifar100,\n",
        "      validation_data = (test_images_cifar100, test_labels_cifar100),\n",
        "      epochs = Nombre_epochs\n",
        "  )\n",
        "\n",
        "  #Showing the results\n",
        "  x_axis = np.linspace(2,Nombre_epochs+1,1)\n",
        "  plt.plot(history.history['accuracy'],label = \"Précision de l'entrainement\")\n",
        "  plt.plot(history.history['val_accuracy'],label=\"Précision des tests\")\n",
        "  plt.title(\"Valeur de la précision de l'entrainement et de l'évaluation en fonction des epochs\")\n",
        "  plt.xlabel(\"Nombre d'epochs\")\n",
        "  plt.ylabel(\"Taux de précision\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "##################################################################################################\n",
        "###################################################################################################\n",
        "\n",
        "print(\"Bienvenue dans l'apprentissage / Welcome to the learning object program \\n\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Voici les possibilités/ Tests possibilities:\\n\")\n",
        "print(\"1 : Pour la librairie Cifar10 / Cifar10 library\")\n",
        "print(\"2 : Pour la librairie mnist (avec matrice de confusion) / Mnist Library\")\n",
        "print(\"3 : Pour la librairie Cifar100 / Cifar100 Library\\n\")\n",
        "\n",
        "while(1):\n",
        "  \n",
        "  i = int(input(\"Choix / Choice : \"))\n",
        "\n",
        "  j = int(input(\"Choisir le nombre d'epoch / Number of epochs : \"))\n",
        "\n",
        "  if(i != 2):\n",
        "    k = str(input(\"Prétraitement gris 'oui' ou 'non' / Gray pre-processing 'yes' or 'no': \"))\n",
        "\n",
        "  if (j >0) :\n",
        "    if(i==1):\n",
        "      if (k == \"oui\" or k == \"yes\"):\n",
        "        cifar10testgris(j)\n",
        "      elif (k==\"non\" or k == \"no\"):\n",
        "        cifar10test(j)\n",
        "      else:\n",
        "        print(\"/!\\ Problème prétraitement / Problem with pre-processing input choice /!\\ \")\n",
        "    \n",
        "    elif(i==2):\n",
        "      mnisttest(j)\n",
        "      \n",
        "\n",
        "    elif(i==3):\n",
        "      if (k == \"oui\" or k == \"yes\"):\n",
        "        cifar100testgris(j)\n",
        "      elif (k==\"non\" or k == \"no\"):\n",
        "        cifar100test(j)\n",
        "      else:\n",
        "        print(\"/!\\ Problème prétraitement / Problem with pre-processing input choice /!\\ \")\n",
        "        \n",
        "    \n",
        "    else:\n",
        "        print(\"\\n\\n\\n/!\\ Entrée non reconnu / Unrecognized input /!\\ \\n\\n\\n\")\n",
        "  else:\n",
        "    print(\"\\n\\n\\n/!\\ Nombre d'epoch nul ou négatif ! / Epochs input invalid /!\\ \\n\\n\\n\")      \n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bienvenue dans l'apprentissage / Welcome to the learning object program \n",
            "\n",
            "\n",
            "\n",
            "Voici les possibilités/ Tests possibilities:\n",
            "\n",
            "1 : Pour la librairie Cifar10 / Cifar10 library\n",
            "2 : Pour la librairie mnist (avec matrice de confusion) / Mnist Library\n",
            "3 : Pour la librairie Cifar100 / Cifar100 Library\n",
            "\n",
            "Choix / Choice : 4\n",
            "Choisir le nombre d'epoch / Number of epochs : 2\n",
            "Prétraitement gris 'oui' ou 'non' / Gray pre-processing 'yes' or 'no': yes\n",
            "/!\\ Entrée non reconnu / Unrecognized input /!\\ \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9d5af1c5738c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Choix / Choice : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m   \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Choisir le nombre d'epoch / Number of epochs : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg0mAVZiyRPL"
      },
      "source": [
        "# **Pour faire une prédiction sur la librairie Cifar10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw4T5jwxLhww"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import *\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "from random import sample, randint\n",
        "\n",
        "epochs_nombre = int(input(\"Nombre d'epochs pour l'entrainement : \"))\n",
        "\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(training_images, training_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "training_images = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in training_images])\n",
        "test_images = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in test_images])\n",
        "\n",
        "training_images = training_images/255\n",
        "test_images = test_images/255\n",
        "\n",
        "modelCNN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(128,3,padding=\"same\",input_shape=(32,32,1),activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Conv2D(64,3,padding=\"same\",activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Conv2D(16,3,padding=\"same\",activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10,activation=\"softmax\")\n",
        "])\n",
        "\n",
        "training_images = np.expand_dims(training_images,3)\n",
        "test_images = np.expand_dims(test_images,3)\n",
        "\n",
        "\n",
        "modelCNN.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "modelCNN.fit(\n",
        "    training_images,\n",
        "    training_labels,\n",
        "    validation_data = (test_images,test_labels),\n",
        "    epochs = epochs_nombre\n",
        ")\n",
        "\n",
        "labels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'];\n",
        "list_images = list(test_images)\n",
        "while (True):\n",
        "    random_image = sample(list_images, 1)\n",
        "    random_image = np.array(random_image, dtype='float')\n",
        "\n",
        "    predict_random = modelCNN.predict(random_image)\n",
        "\n",
        "    random_pred = np.argmax(predict_random)\n",
        "\n",
        "    random_image = random_image.reshape((32, 32))\n",
        "    plt.imshow(random_image)\n",
        "    plt.title(\"résultat prédit : \" + str(labels[random_pred]))\n",
        "    plt.show()\n",
        "\n",
        "    if input(\"Afficher un autre exemple ? oui/non : \") == \"non\":\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(modelCNN.summary())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}